services:
  redis-service:
    image: docker.io/library/redis:7-alpine
    ports: ["6379:6379"]

  chroma-service:
    image: chromadb/chroma:latest
    ports: ["8000:8000"]
    volumes:
      - ./PV/Chroma:/chroma/chroma
    environment:
      - PERSIST_DIRECTORY=/chroma/chroma
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    command: ["run", "--host", "0.0.0.0", "--port", "8000", "--path", "/chroma/chroma"]

  image-server:
    image: docker.io/library/python:3.11-slim
    command: ["python", "-m", "http.server", "8000", "--directory", "/images"]
    volumes:
      - ./PV/Images:/images:ro
    ports: ["8090:8000"]

  router-model:
    image: ghcr.io/ggml-org/llama.cpp:server
    volumes:
      - ./PV/GGUF:/models:ro
    ports: ["8081:8081"]
    command: >
      -m /models/Qwen3-VL-2B-Instruct-Q4_K_M.gguf
      --host 0.0.0.0
      --port 8081
      -c 1024
      --chat-template-file /models/qwen3_fixed_template.jinja
      --jinja
      --temp 1.0
      --top-p 0.95
      --presence-penalty 0.0
      --threads 6

  vision-small-model:
    image: ghcr.io/ggml-org/llama.cpp:server
    volumes:
      - ./PV/GGUF:/models:ro
    ports: ["8082:8082"]
    command: >
      -m /models/Qwen3-VL-4B-Instruct-Q4_K_M.gguf
      --mmproj /models/mmproj-4b.gguf
      --host 0.0.0.0
      --port 8082
      -c 4096
      --chat-template-file /models/qwen3_fixed_template.jinja
      --jinja
      --temp 0.7
      --top-p 0.8
      --presence-penalty 1.5
      --threads 6

  vision-large-model:
    image: ghcr.io/ggml-org/llama.cpp:server
    volumes:
      - ./PV/GGUF:/models:ro
    ports: ["8083:8083"]
    command: >
      -m /models/Qwen3-VL-8B-Thinking-Q4_K_M.gguf
      --mmproj /models/mmproj-model-f16.gguf
      --host 0.0.0.0
      --port 8083
      -c 4096
      --chat-template-file /models/qwen3_fixed_template.jinja
      --jinja
      --temp 1.0
      --top-p 0.95
      --presence-penalty 0.0
      --threads 6

  embed-model:
    image: ghcr.io/ggml-org/llama.cpp:server
    volumes:
      - ./PV/GGUF:/models:ro
    ports: ["8084:8084"]
    command: >
      -m /models/nomic-embed-text-v2-moe.Q6_K.gguf
      --host 0.0.0.0
      --port 8084
      --embedding
      --threads 6

  interface:
    build:
      context: ./interface
      dockerfile: Dockerfile.interface
    ports: ["8080:8080"]
    environment: [REDIS_HOST=redis-service]
    depends_on: [redis-service]

  camera_agent:
    build:
      context: ./camera_agent
      dockerfile: Dockerfile.camera_agent
    devices: ["/dev/video0:/dev/video0"]  # Keep webcam fallback
    volumes: [./PV/Images:/app/images]
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis-service
      - NODE_NAME=wyze_camera  # Changed from local_laptop
      - CAMERA_INDEX=0
      - IMAGE_DIR=/app/images
      - BACKGROUND_INTERVAL=30  # More frequent updates
      # Thingino RTSP Configuration
      - RTSP_URLS=rtsp://thingino:thingino@192.168.1.11/ch0
      - RTSP_CROP_TOP=55  # Based on your GIMP measurement
      - RTSP_THROWAWAY_FRAMES=5
      - RTSP_TIMEOUT_MS=10000
      - ENABLE_WEBCAM_FALLBACK=true
    depends_on: [redis-service]

  route:
    build:
      context: ./route
      dockerfile: Dockerfile.route
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis-service
      - LLM_URL=http://router-model:8081/v1
    depends_on: [redis-service, router-model]

  vision_small:
    build:
      context: ./vision_small
      dockerfile: Dockerfile.vision_small
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis-service
      - LLM_URL=http://vision-small-model:8082/v1
      - IMAGE_SERVER_URL=http://image-server:8000
    depends_on: [redis-service, vision-small-model, image-server]

  vision_large:
    build:
      context: ./vision_large
      dockerfile: Dockerfile.vision_large
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis-service
      - LLM_URL=http://vision-large-model:8083/v1
      - IMAGE_SERVER_URL=http://image-server:8000
    depends_on: [redis-service, vision-large-model, image-server]

  embed:
    build:
      context: ./embed
      dockerfile: Dockerfile.embed
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis-service
      - CHROMA_HOST=chroma-service
      - LLM_URL=http://embed-model:8084/v1
      - IMAGE_SERVER_URL=http://image-server:8000
    depends_on: [redis-service, chroma-service, embed-model]
